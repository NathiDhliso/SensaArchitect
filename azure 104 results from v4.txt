________________________________________
AZ-104: MICROSOFT AZURE ADMINISTRATOR - VISUAL MASTER HIERARCHICAL CHART
1. SOURCE VERIFICATION
Official Source: Microsoft Learn Study Guide for Exam AZ-104 (Skills Measured as of April 18, 2025)
Three Recent Updates (Last 12 Months):
1.	Configure soft delete for blobs and containers - Added April 18, 2025 to the Storage domain (first exam update in 18 months)
2.	Manage sizing and scaling for containers - Enhanced emphasis on Azure Container Instances and Azure Container Apps scaling operations
3.	Export deployments and convert between ARM/Bicep - Expanded Infrastructure as Code requirements for bidirectional template conversion
Critical Numerical Limits Found:
•	Exam Weight Distribution: Identities/Governance (20-25%), Storage (15-20%), Compute (20-25%), Networking (15-20%), Monitoring (10-15%)
•	Exam Retake Policy: 24-hour minimum wait after first attempt
•	[Verify in Docs]: Specific soft delete retention periods, container size limits, NSG rule priority ranges, and backup RPO/RTO metrics require verification in current Azure documentation
Limitation Note: Specific Azure service limits (VM core quotas, storage account IOPS thresholds, NSG rule counts) change frequently and are not published in the exam guide itself. These must be verified in Azure documentation during preparation.
________________________________________
2. LIFECYCLE DEFINITION
Selected Cycle: IT/Cloud: PROVISION → CONFIGURE → MONITOR
Justification: The AZ-104 exam explicitly tests Azure Administrator capabilities across the entire resource lifecycle: creating resources (Provision), setting policies/security/networking (Configure), and using Azure Monitor/diagnostic tools (Monitor). This three-phase pattern appears consistently across all five exam domains and aligns with Microsoft's "implement, manage, and monitor" role description for Azure administrators.
________________________________________
3. MASTER HIERARCHICAL CHART
AZ-104: MICROSOFT AZURE ADMINISTRATOR
═══════════════════════════════════════════════════════════════════════

# DOMAIN 1: MANAGE AZURE IDENTITIES AND GOVERNANCE (20-25%)

## CORE CONCEPT 1: Microsoft Entra Users and Groups
PROVISION (The Foundation)
  - Prerequisite: Valid Azure subscription with Owner or User Access Administrator role
  - Selection: Cloud-Only Identity vs. Hybrid Identity (synced from on-premises AD)
  - Execution: Azure Portal → Microsoft Entra ID → Users/Groups blade OR PowerShell: New-MgUser

CONFIGURE (The Configuration)
  • Assign Licenses: Direct Assignment vs. Group-Based Licensing
  • Configure User Properties: UsageLocation (Required for license assignment), Job Title, Department
  • Enable Self-Service Password Reset (SSPR): Authentication Methods (minimum 2 required: Mobile App, Email, Security Questions)
  • [Critical Distinction]: Dynamic Groups vs. Assigned Groups - Dynamic uses membership rules (user.department -eq "IT"), Assigned requires manual add/remove
  • [Requirement]: External B2B users require invitation redemption before accessing resources

MONITOR (The Verification)
  ○ Tool/Document: Microsoft Entra ID Sign-In Logs (Azure Portal → Microsoft Entra ID → Monitoring → Sign-ins)
  ○ Metric/Deadline: Monitor failed sign-in attempts, Conditional Access policy hits, MFA success rates
  ○ Tool/Document: Audit Logs for user/group creation, deletion, and property changes


## CORE CONCEPT 2: Role-Based Access Control (RBAC)
PROVISION (The Foundation)
  - Prerequisite: User Access Administrator or Owner role at the scope where assignment will occur
  - Selection: Built-in Roles (Owner, Contributor, Reader, plus 70+ service-specific roles) vs. Custom Roles
  - Execution: Azure Portal → Resource/Resource Group/Subscription → Access Control (IAM) → Add Role Assignment

CONFIGURE (The Configuration)
  • Scope Assignment: Management Group > Subscription > Resource Group > Resource (inheritance flows downward)
  • [Critical Distinction]: Contributor vs. Owner - Contributor can manage resources but CANNOT grant access; Owner can do both
  • [Critical Distinction]: Reader vs. Reader and Data Access - Reader sees metadata only; Reader and Data Access can read blob/queue data
  • Apply Deny Assignments: Azure Blueprints and managed applications can create system-protected deny assignments
  • [Exam Alert]: Role assignments can take up to 30 minutes to propagate globally

MONITOR (The Verification)
  ○ Tool/Document: Access Control (IAM) → Check Access blade (shows effective permissions for specific user)
  ○ Tool/Document: Activity Log filtered by Category: "Administrative" to track role assignment changes
  ○ Metric/Deadline: Review role assignments quarterly for least-privilege compliance


## CORE CONCEPT 3: Azure Policy and Governance
PROVISION (The Foundation)
  - Prerequisite: Owner, Contributor, or Resource Policy Contributor role at target scope
  - Selection: Built-in Policy Definitions (400+ available) vs. Custom Policy Definitions (JSON-based)
  - Execution: Azure Portal → Policy → Definitions → Assign Policy OR Azure CLI: az policy assignment create

CONFIGURE (The Configuration)
  • Define Policy Parameters: Allowed Locations, Allowed VM SKUs, Required Tags
  • Set Enforcement Mode: Default (enforce) vs. DoNotEnforce (audit-only mode for testing)
  • Configure Remediation Task: Create remediation for non-compliant existing resources (requires Managed Identity with appropriate permissions)
  • [Critical Distinction]: Policy vs. RBAC - Policy controls WHAT resources can be created; RBAC controls WHO can create resources
  • [Requirement]: Policies assigned at Management Group scope inherit to all child subscriptions
  • [Constraint]: Policy evaluation occurs at resource create/update time, plus scheduled compliance scans every 24 hours

MONITOR (The Verification)
  ○ Tool/Document: Policy → Compliance dashboard (shows compliant vs. non-compliant resource counts)
  ○ Metric/Deadline: Target 100% compliance for security/regulatory policies; investigate non-compliance within 48 hours
  ○ Tool/Document: Activity Log Category: "Policy" for policy assignment and evaluation events


## CORE CONCEPT 4: Resource Management and Tagging
PROVISION (The Foundation)
  - Prerequisite: Contributor role or higher at target scope
  - Selection: Resource Group Deployment Model (all resources require a resource group)
  - Execution: Azure Portal → Resource Groups → Create OR Azure CLI: az group create

CONFIGURE (The Configuration)
  • Apply Resource Locks: ReadOnly (prevents modifications) vs. CanNotDelete (allows changes, prevents deletion)
  • [Critical Distinction]: ReadOnly Lock vs. Delete Lock - ReadOnly blocks PUT operations including updates; CanNotDelete only blocks DELETE
  • Apply Tags: Key-value pairs (max 50 tags per resource, key max 512 chars, value max 256 chars)
  • [Requirement]: Tags do NOT inherit from resource groups to child resources (must apply policy for enforcement)
  • Configure Cost Management: Set budgets with alert thresholds (50%, 75%, 90%, 100% of budget)
  • Implement Management Groups: Hierarchy of up to 6 levels below root (excludes root itself)

MONITOR (The Verification)
  ○ Tool/Document: Cost Management + Billing → Cost Analysis (view spending by tag, resource group, service)
  ○ Tool/Document: Azure Advisor → Cost Recommendations (identifies underutilized resources)
  ○ Metric/Deadline: Review cost alerts monthly; investigate anomalies exceeding 20% of projected spend


## CORE CONCEPT 5: Azure Subscriptions
PROVISION (The Foundation)
  - Prerequisite: Account Administrator (classic) or Billing Account Owner (modern) to create subscriptions
  - Selection: Subscription Type: Pay-As-You-Go, Enterprise Agreement (EA), Microsoft Customer Agreement (MCA)
  - Execution: Azure Portal → Subscriptions → Add OR Enterprise Agreement Portal for EA subscriptions

CONFIGURE (The Configuration)
  • Transfer Subscription Ownership: Source account must be Account Administrator; target accepts via email
  • Cancel Subscription: Resources are soft-deleted (90-day recovery period for Pay-As-You-Go)
  • [Requirement]: Moving resources between subscriptions requires resources to support the move operation (check Azure documentation)
  • Configure Service Limits: Default quotas exist for VM cores, public IPs, storage accounts (request increases via support ticket)
  • [Exam Alert]: Resource dependencies (VMs attached to VNets) must move together or require re-creation

MONITOR (The Verification)
  ○ Tool/Document: Subscriptions → Usage + Quotas blade (displays current usage vs. subscription limits)
  ○ Tool/Document: Service Health → Resource Health (subscription-level service incidents)
  ○ Metric/Deadline: Monitor quota usage; request increases when approaching 80% of limits


═══════════════════════════════════════════════════════════════════════

# DOMAIN 2: IMPLEMENT AND MANAGE STORAGE (15-20%)

## CORE CONCEPT 6: Storage Account Configuration
PROVISION (The Foundation)
  - Prerequisite: [None] - Any Azure subscription can create storage accounts
  - Selection: Performance Tier: Standard (HDD) vs. Premium (SSD) - cannot change after creation
  - Selection: Redundancy: LRS (3 copies local) vs. ZRS (3 zones) vs. GRS (geo-replicated) vs. GZRS (zone + geo)
  - Execution: Azure Portal → Storage Accounts → Create OR Azure CLI: az storage account create

CONFIGURE (The Configuration)
  • Configure Access Tier: Hot (frequent access, higher storage cost) vs. Cool (30-day min, lower storage cost) vs. Archive (180-day min, lowest cost)
  • [Critical Distinction]: Account-Level Access Tier vs. Blob-Level Access Tier - Account tier is default; individual blobs can override
  • Enable Soft Delete for Blobs: Retention period 1-365 days (default 7 days) - NEW EXAM REQUIREMENT April 2025
  • Enable Soft Delete for Containers: Retention period 1-365 days - NEW EXAM REQUIREMENT April 2025
  • Configure Storage Firewalls: Default Deny with Allow rules for specific VNets/Subnets/IP ranges
  • Enable Hierarchical Namespace: Required for Azure Data Lake Storage Gen2 (cannot enable after creation)
  • [Requirement]: Premium Block Blob accounts support only LRS and ZRS redundancy

MONITOR (The Verification)
  ○ Tool/Document: Storage Account → Monitoring → Metrics (Transactions, Ingress/Egress, Success %)
  ○ Tool/Document: Azure Storage Explorer (desktop app) for browsing/managing blobs, files, queues, tables
  ○ Metric/Deadline: Monitor Availability metric (target: >99.9% for GRS/GZRS); alert on SuccessE2ELatency >1000ms


## CORE CONCEPT 7: Storage Account Security and Access
PROVISION (The Foundation)
  - Prerequisite: Storage Account must exist; Owner or Storage Account Contributor role required
  - Selection: Access Method: Storage Account Keys (full access) vs. Shared Access Signature (SAS - delegated access) vs. Azure AD (identity-based)
  - Execution: Azure Portal → Storage Account → Security + Networking → Access Keys

CONFIGURE (The Configuration)
  • Rotate Access Keys: Storage accounts have 2 keys (key1, key2); rotate without downtime by regenerating alternate key
  • [Critical Distinction]: Account SAS vs. Service SAS vs. User Delegation SAS - User Delegation is Azure AD-backed (most secure)
  • Configure SAS Token: Start Time, Expiry Time, Allowed IPs, Allowed Protocols (HTTPS only recommended)
  • Create Stored Access Policy: Named policy attached to container/share allowing SAS revocation by deleting policy
  • [Requirement]: SAS tokens cannot be revoked individually; only via Stored Access Policy deletion or key regeneration
  • Enable Azure AD Authentication for Blobs/Queues: Assign Storage Blob Data Reader/Contributor roles
  • Configure Identity-Based Access for Azure Files: Requires AD DS or Azure AD DS integration
  • [Exam Alert]: Storage Account Keys grant FULL access to all data; use SAS or Azure AD for least privilege

MONITOR (The Verification)
  ○ Tool/Document: Storage Account → Monitoring → Diagnostic Settings → Send logs to Log Analytics Workspace
  ○ Tool/Document: Query StorageBlobLogs table in Log Analytics for access patterns, 403 errors
  ○ Metric/Deadline: Review SAS token usage monthly; rotate keys quarterly per security policy


## CORE CONCEPT 8: Azure Blob Storage
PROVISION (The Foundation)
  - Prerequisite: Storage Account (General Purpose v2 or Blob Storage account type)
  - Selection: Container Access Level: Private (no anonymous) vs. Blob (anonymous read for blobs only) vs. Container (anonymous read for container + blobs)
  - Execution: Azure Portal → Storage Account → Containers → + Container OR AzCopy: azcopy make

CONFIGURE (The Configuration)
  • Configure Blob Versioning: Automatically maintains previous versions of blobs (enabled at storage account level)
  • Configure Blob Lifecycle Management: Rules to transition blobs between tiers or delete based on age
  • [Example Rule]: Move to Cool tier if not modified for 30 days, Archive after 90 days, Delete after 365 days
  • Enable Soft Delete for Blobs: Allows recovery of deleted blobs within retention period (NEW April 2025 emphasis)
  • Enable Soft Delete for Containers: Allows recovery of deleted containers within retention period (NEW April 2025 emphasis)
  • [Critical Distinction]: Blob Snapshots vs. Blob Versions - Snapshots are manual point-in-time copies; Versions are automatic on every write
  • Configure Object Replication: Async replication between storage accounts (requires blob versioning enabled on both)
  • [Requirement]: Object replication requires source and destination storage accounts in different regions for geo-redundancy

MONITOR (The Verification)
  ○ Tool/Document: Azure Storage Explorer → Blob Containers → View soft-deleted containers/blobs
  ○ Tool/Document: Storage Account → Data Management → Lifecycle Management → View policy execution logs
  ○ Metric/Deadline: Monitor BlobCapacity metric; alert when approaching storage account limits (500 TB for GPv2)


## CORE CONCEPT 9: Azure Files
PROVISION (The Foundation)
  - Prerequisite: Storage Account (General Purpose v1, v2, or FileStorage for premium)
  - Selection: Performance: Standard (HDD, 100 TB max) vs. Premium (SSD, 100 TB max per share)
  - Selection: Protocol: SMB (Windows/Linux/macOS) vs. NFS (Linux only, requires premium storage)
  - Execution: Azure Portal → Storage Account → File Shares → + File Share

CONFIGURE (The Configuration)
  • Configure Quota: Maximum size for file share (1 GiB to 100 TiB for standard, 100 GiB to 100 TiB for premium)
  • Enable Identity-Based Authentication: Active Directory Domain Services (AD DS) or Azure AD DS integration required
  • [Requirement]: AD DS integration requires storage account registration in on-premises AD (using AzFilesHybrid PowerShell module)
  • Configure Soft Delete for File Shares: Retention period 1-365 days (default 7 days)
  • Create Snapshots: Share-level read-only point-in-time copies (up to 200 snapshots per share)
  • [Critical Distinction]: File Share Snapshots vs. Backup - Snapshots are manual/API-based; Azure Backup provides scheduled policy-based protection
  • Configure SMB Security: SMB 3.x with encryption in transit (default); can enforce SMB 3.1.1 for maximum security
  • Mount File Share: Windows (net use Z: \\storageaccount.file.core.windows.net\share), Linux (mount via CIFS)

MONITOR (The Verification)
  ○ Tool/Document: Storage Account → Monitoring → File Share Insights (shows IOPS, throughput, latency)
  ○ Tool/Document: Azure Backup Reports for protected file shares (RPO compliance, restore success rate)
  ○ Metric/Deadline: Monitor Transactions metric; alert on Error responses (authorization failures, quota exceeded)


## CORE CONCEPT 10: Data Transfer and Management Tools
PROVISION (The Foundation)
  - Prerequisite: AzCopy CLI tool installed OR Azure Storage Explorer desktop application
  - Selection: Tool Choice: AzCopy (CLI bulk transfers), Storage Explorer (GUI management), Azure Data Box (physical appliance for TB/PB transfers)
  - Execution: Download from microsoft.com/azcopy or install Storage Explorer from microsoft.com

CONFIGURE (The Configuration)
  • AzCopy Authentication: Azure AD (azcopy login) vs. SAS Token (append to URL)
  • Common AzCopy Commands:
    - Copy: azcopy copy 'source' 'destination' [--recursive]
    - Sync: azcopy sync 'source' 'destination' (one-way sync, deletes extra files at destination)
    - Remove: azcopy remove 'target' [--recursive]
  • [Critical Distinction]: AzCopy Copy vs. Sync - Copy adds/updates only; Sync also DELETES files at destination not present at source
  • Configure Concurrency: --cap-mbps flag to limit bandwidth, --block-size-mb for large file optimization
  • Azure Storage Explorer Features: Manage RBAC, SAS tokens, Stored Access Policies, lifecycle policies via GUI
  • [Exam Alert]: For initial large data loads (>10 TB), Azure Data Box appliance may be more cost-effective than network transfer

MONITOR (The Verification)
  ○ Tool/Document: AzCopy job logs (stored in %USERPROFILE%\.azcopy directory on Windows)
  ○ Tool/Document: Storage Account → Monitoring → Metrics (Ingress/Egress to validate transfer rates)
  ○ Metric/Deadline: Verify transfer completion via source/destination file count comparison; investigate failures in job logs


═══════════════════════════════════════════════════════════════════════

# DOMAIN 3: DEPLOY AND MANAGE AZURE COMPUTE RESOURCES (20-25%)

## CORE CONCEPT 11: Infrastructure as Code (ARM Templates and Bicep)
PROVISION (The Foundation)
  - Prerequisite: Understanding of JSON (ARM templates) or Bicep declarative syntax
  - Selection: ARM Template (JSON) vs. Bicep (human-readable DSL that compiles to ARM JSON)
  - Execution: Azure Portal → Resource Group → Export Template OR VS Code with Bicep extension

CONFIGURE (The Configuration)
  • ARM Template Structure: $schema, contentVersion, parameters, variables, resources, outputs
  • Bicep File Structure: Simplified syntax - no contentVersion, cleaner resource declarations
  • Convert ARM to Bicep: Azure CLI command: az bicep decompile --file template.json
  • Convert Bicep to ARM: Automatic compilation when deploying, or explicit: az bicep build --file main.bicep
  • [Critical Distinction]: ARM Template deployment modes - Incremental (add/update only) vs. Complete (deletes resources not in template)
  • Deploy Template: Azure CLI: az deployment group create --resource-group RG --template-file template.json
  • [Requirement]: Parameters file (parameters.json) separates environment-specific values from template structure
  • [Exam Alert]: Complete deployment mode is DANGEROUS - deletes all resources in RG not defined in template

MONITOR (The Verification)
  ○ Tool/Document: Azure Portal → Resource Group → Deployments (view deployment history, errors, outputs)
  ○ Tool/Document: Activity Log filtered by Operation Name: "Create Deployment" to track template deployments
  ○ Metric/Deadline: Validate deployment outputs match expected values; revert failed deployments within 1 hour


## CORE CONCEPT 12: Azure Virtual Machines
PROVISION (The Foundation)
  - Prerequisite: Virtual Network and Subnet must exist (or create during VM provisioning)
  - Selection: VM Size: General Purpose (D-series), Compute Optimized (F-series), Memory Optimized (E-series), GPU (N-series)
  - Selection: Image: Marketplace (Windows Server, Ubuntu, RHEL) vs. Custom Image vs. Managed Disk snapshot
  - Execution: Azure Portal → Virtual Machines → Create OR Azure CLI: az vm create

CONFIGURE (The Configuration)
  • Attach Data Disks: Managed Disks (Standard HDD, Standard SSD, Premium SSD, Ultra Disk) - max count varies by VM size
  • [Critical Distinction]: OS Disk vs. Data Disk - OS disk has max 4 TB (newer VMs support 1 TB+ with GPT); data disks up to 32 TB
  • Enable Azure Disk Encryption: Uses BitLocker (Windows) or dm-crypt (Linux); requires Key Vault for key storage
  • [Requirement]: Azure Disk Encryption requires VM to have Managed Disks (not unmanaged VHDs)
  • Resize VM: Change VM size (requires deallocation); verify target size supports existing disk/network configuration
  • Move VM: Between resource groups (same subscription), between subscriptions, or between regions (using Azure Site Recovery)
  • [Constraint]: Moving VM between regions requires downtime; plan maintenance window
  • Configure Availability: Availability Sets (99.95% SLA, 3 Fault Domains, 20 Update Domains) vs. Availability Zones (99.99% SLA, 3 separate zones)
  • [Exam Alert]: Cannot add existing VM to Availability Set after creation - must recreate VM

MONITOR (The Verification)
  ○ Tool/Document: VM → Monitoring → Metrics (Percentage CPU, Disk IOPS, Network In/Out)
  ○ Tool/Document: Boot Diagnostics (requires storage account) - captures serial console logs and screenshots
  ○ Metric/Deadline: Alert on CPU >80% sustained for 15 minutes; investigate disk queue depth >10


## CORE CONCEPT 13: Virtual Machine Scale Sets (VMSS)
PROVISION (The Foundation)
  - Prerequisite: Virtual Network and Subnet with sufficient IP space for scale-out scenarios
  - Selection: Orchestration Mode: Uniform (identical VMs, load balancer integration) vs. Flexible (mixed VM sizes, manual management)
  - Selection: Scaling Policy: Manual, Scheduled, Metrics-based (CPU, memory, custom metrics)
  - Execution: Azure Portal → Virtual Machine Scale Sets → Create OR Azure CLI: az vmss create

CONFIGURE (The Configuration)
  • Configure Autoscale Rules: Scale out when CPU >70% for 10 min, Scale in when CPU <30% for 10 min
  • Set Instance Limits: Minimum instance count (e.g., 2), Maximum instance count (e.g., 10)
  • [Critical Distinction]: Scale Out vs. Scale Up - Scale Out adds more VM instances; Scale Up increases size of existing VMs
  • Enable Automatic OS Upgrades: Requires health probe configuration to validate instance health before upgrade
  • Configure Upgrade Policy: Automatic (rolling updates), Manual (admin controls), Rolling (staged updates with health checks)
  • [Requirement]: Health probe or Application Health Extension required for safe rolling upgrades
  • Deploy across Availability Zones: Distributes instances across zones (requires zone-redundant load balancer)

MONITOR (The Verification)
  ○ Tool/Document: VMSS → Monitoring → Autoscale History (shows scale events, metrics that triggered scaling)
  ○ Tool/Document: VMSS → Instances blade (view health status of individual instances)
  ○ Metric/Deadline: Monitor scale-in/out latency; target <5 minutes from trigger to new instance ready


## CORE CONCEPT 14: Azure Container Instances (ACI)
PROVISION (The Foundation)
  - Prerequisite: Container image available in Azure Container Registry, Docker Hub, or other registry
  - Selection: OS Type: Linux vs. Windows containers (Windows limited availability)
  - Selection: Resource Allocation: CPU cores (0.1-4 cores) and Memory (0.1-16 GB) per container
  - Execution: Azure Portal → Container Instances → Create OR Azure CLI: az container create

CONFIGURE (The Configuration)
  • Configure Networking: Public IP + DNS Name Label vs. VNet Integration (private IP)
  • [Requirement]: VNet integration requires subnet delegation to Microsoft.ContainerInstance/containerGroups
  • Set Restart Policy: Always (continuous services), OnFailure (batch jobs), Never (one-time tasks)
  • Configure Environment Variables: Plain text vs. Secure values (hidden in portal/CLI output)
  • Mount Azure Files Volume: Requires storage account key or SAS token; supports SMB shares
  • [Critical Distinction]: Container Groups vs. Single Containers - Container Group = pod-like concept (shared network/storage)
  • Scale Container Instances: Manual scaling only - no autoscale (use AKS or Container Apps for autoscale)
  • [Exam Alert]: ACI billing is per-second for CPU/memory allocation, not container running time

MONITOR (The Verification)
  ○ Tool/Document: Container Instance → Containers → Logs (stdout/stderr streams)
  ○ Tool/Document: Container Instance → Containers → Connect (interactive terminal/exec)
  ○ Metric/Deadline: Monitor CpuUsage and MemoryUsage metrics; alert on memory approaching 90% of allocated


## CORE CONCEPT 15: Azure Container Apps
PROVISION (The Foundation)
  - Prerequisite: Container App Environment (managed Kubernetes cluster abstraction)
  - Selection: Ingress Configuration: External (internet-facing) vs. Internal (VNet only) vs. Disabled (background jobs)
  - Selection: Scale Rules: HTTP-based, CPU/Memory, Custom (Azure Queue, Kafka, etc.)
  - Execution: Azure Portal → Container Apps → Create OR Azure CLI: az containerapp create

CONFIGURE (The Configuration)
  • Configure Scaling: Min replicas (0 for event-driven, ≥1 for always-on), Max replicas (default 10)
  • [Critical Distinction]: Container Apps vs. ACI - Container Apps support autoscale, revisions, traffic splitting; ACI is simpler single-container
  • Enable Dapr (Distributed Application Runtime): Sidecar pattern for service-to-service calls, state management, pub/sub
  • Configure Revisions: Immutable snapshots of container app configuration; supports blue/green deployments
  • Traffic Splitting: Percentage-based routing between multiple revisions (Revision A: 80%, Revision B: 20%)
  • [Requirement]: Scale-to-zero requires Min Replicas = 0 and appropriate scale trigger (HTTP requests, queue messages)
  • Configure Secrets: Store connection strings, API keys (referenced in environment variables or volume mounts)

MONITOR (The Verification)
  ○ Tool/Document: Container App → Monitoring → Log Stream (real-time logs from all replicas)
  ○ Tool/Document: Container App → Revision Management (view active revisions, traffic distribution)
  ○ Metric/Deadline: Monitor Requests metric; alert on HTTP 5xx errors >1% of total requests


## CORE CONCEPT 16: Azure Container Registry (ACR)
PROVISION (The Foundation)
  - Prerequisite: [None] - Any Azure subscription can create ACR
  - Selection: SKU: Basic (dev/test, 10 GB storage), Standard (production, 100 GB storage), Premium (geo-replication, 500 GB storage)
  - Execution: Azure Portal → Container Registries → Create OR Azure CLI: az acr create

CONFIGURE (The Configuration)
  • Enable Admin User: Provides username/password authentication (not recommended for production - use Azure AD)
  • Configure Geo-Replication: Premium SKU only - replicate registry to multiple regions for HA/DR
  • [Requirement]: Geo-replication requires Premium SKU and separate replication configuration for each target region
  • Import Container Images: az acr import --name myregistry --source docker.io/library/nginx:latest
  • Configure Webhooks: Trigger notifications/actions on push, delete, chart push/delete events
  • [Critical Distinction]: ACR Tasks vs. Docker Build - ACR Tasks build images in Azure (no local Docker required)
  • Build Image in ACR: az acr build --registry myregistry --image myapp:v1 .
  • Integrate with AKS: az aks update --attach-acr myregistry (grants AKS managed identity pull permissions)

MONITOR (The Verification)
  ○ Tool/Document: ACR → Repositories (view images, tags, sizes, pull counts)
  ○ Tool/Document: ACR → Networking → Firewall logs (track allowed/denied access attempts)
  ○ Metric/Deadline: Monitor StorageUsed metric; alert when approaching SKU limit (10/100/500 GB)


## CORE CONCEPT 17: Azure App Service
PROVISION (The Foundation)
  - Prerequisite: App Service Plan (defines compute resources) must exist or be created with app
  - Selection: App Service Plan SKU: Free/Shared (shared compute), Basic (dedicated, no autoscale), Standard/Premium (autoscale, slots, VNet)
  - Selection: Runtime Stack: .NET, Java, Node.js, Python, PHP, Ruby (Linux only), Static HTML, or Container
  - Execution: Azure Portal → App Services → Create OR Azure CLI: az webapp create

CONFIGURE (The Configuration)
  • Scale App Service Plan: Scale Up (change SKU/pricing tier) vs. Scale Out (add more instances)
  • [Critical Distinction]: Scale Up vs. Scale Out - Scale Up increases resources per instance; Scale Out adds instances for horizontal scaling
  • Configure Autoscale: Rules based on CPU %, Memory %, HTTP Queue Length, Custom Metrics
  • [Requirement]: Autoscale requires Standard tier or higher App Service Plan
  • Configure Deployment Slots: Staging, Pre-Production (Standard tier: 5 slots, Premium: 20 slots)
  • Swap Deployment Slots: Warm-up occurs automatically; swap can be aborted before production receives traffic
  • [Exam Alert]: Slot settings (marked "slot setting") do NOT swap during deployment slot swap (e.g., connection strings)
  • Configure Custom Domain: Add DNS TXT/CNAME records, then bind domain in App Service
  • Configure TLS/SSL: Upload certificate OR use App Service Managed Certificate (free, auto-renewed)
  • Enable Backup: Requires Standard tier or higher; backs up app content, configuration, connected SQL/MySQL databases
  • Configure Networking: VNet Integration (outbound), Private Endpoint (inbound), Hybrid Connections (on-premises resources)

MONITOR (The Verification)
  ○ Tool/Document: App Service → Monitoring → App Service Logs (Application logging, Web server logging, Detailed error messages)
  ○ Tool/Document: App Service → Monitoring → Metrics (CPU Time, Memory Working Set, Http Server Errors, Response Time)
  ○ Metric/Deadline: Alert on Http5xx errors >10 in 5 minutes; investigate Response Time P95 >2 seconds


═══════════════════════════════════════════════════════════════════════

# DOMAIN 4: IMPLEMENT AND MANAGE VIRTUAL NETWORKING (15-20%)

## CORE CONCEPT 18: Virtual Networks and Subnets
PROVISION (The Foundation)
  - Prerequisite: [None] - Any subscription can create VNets
  - Selection: Address Space: RFC 1918 private ranges (10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16)
  - Selection: Subnet Design: Plan for growth, reserve space for gateways, Azure Bastion, Azure Firewall
  - Execution: Azure Portal → Virtual Networks → Create OR Azure CLI: az network vnet create

CONFIGURE (The Configuration)
  • Create Subnets: Minimum /29 (8 IPs), Azure reserves 5 IPs per subnet (first 4 + last 1)
  • [Example]: /27 subnet provides 32 IPs total, 27 usable (32 - 5 reserved)
  • [Critical Distinction]: GatewaySubnet vs. Regular Subnet - GatewaySubnet must be named exactly "GatewaySubnet", minimum /29 (recommend /27)
  • Configure Service Endpoints: Enable direct routing to Azure services (Storage, SQL, KeyVault) over Azure backbone
  • [Requirement]: Service Endpoints require subnet-level configuration + service-side firewall rule allowing VNet
  • Configure Subnet Delegation: Delegate subnet to specific service (Azure Container Instances, Azure Databricks, etc.)
  • Add Address Space: Can add non-overlapping address spaces to existing VNet without downtime
  • [Constraint]: Cannot delete address space if subnets or IPs are allocated within it

MONITOR (The Verification)
  ○ Tool/Document: VNet → Subnets blade (view available IPs per subnet, delegation status)
  ○ Tool/Document: Network Watcher → IP Flow Verify (test if traffic is allowed/denied to specific IP)
  ○ Metric/Deadline: Monitor subnet IP exhaustion; expand subnet or add new subnet when >80% allocated


## CORE CONCEPT 19: Virtual Network Peering
PROVISION (The Foundation)
•	Prerequisite: Two VNets with non-overlapping address spaces in same or different regions/subscriptions
•	Selection: Peering Type: Regional (same region) vs. Global (cross-region, additional charges)
•	Execution: Azure Portal → VNet → Peerings → Add OR Azure CLI: az network vnet peering create
CONFIGURE (The Configuration) • Configure Peering Settings: - Allow Virtual Network Access: Enable traffic flow (required) - Allow Forwarded Traffic: Enable traffic forwarded by NVA (network virtual appliance) - Allow Gateway Transit: Hub VNet shares VPN/ExpressRoute gateway with spoke - Use Remote Gateways: Spoke VNet uses hub's gateway (requires Allow Gateway Transit on hub) • [Critical Distinction]: VNet Peering vs. VPN Gateway - Peering uses Azure backbone (lower latency, higher bandwidth); VPN uses encrypted tunnel • [Requirement]: Peering must be created in BOTH directions (VNetA→VNetB AND VNetB→VNetA) • Configure Hub-Spoke Topology: Hub VNet with shared services (gateway, firewall); spokes peer to hub but NOT to each other by default • Enable Spoke-to-Spoke: Requires User-Defined Routes (UDRs) pointing to NVA/Firewall in hub for traffic inspection • [Exam Alert]: Peering is not transitive - if VNetA peers to VNetB, and VNetB peers to VNetC, VNetA cannot reach VNetC without additional config
MONITOR (The Verification) ○ Tool/Document: VNet → Peerings blade (Status: Connected = successful bidirectional peering) ○ Tool/Document: Network Watcher → Connection Monitor (continuous connectivity testing between VNets) ○ Metric/Deadline: Alert on peering Status change from "Connected" to "Disconnected"
CORE CONCEPT 20: Network Security Groups (NSGs)
PROVISION (The Foundation)
•	Prerequisite: VNet and Subnet OR Network Interface (NSGs apply at subnet or NIC level)
•	Selection: Association: Subnet-level (applies to all resources in subnet) vs. NIC-level (applies to single VM)
•	Execution: Azure Portal → Network Security Groups → Create OR Azure CLI: az network nsg create
CONFIGURE (The Configuration) • Create Security Rules: Priority (100-4096, lower number = higher priority), Source/Destination (IP, Service Tag, ASG), Port, Protocol, Action (Allow/Deny) • [Critical Distinction]: Inbound Rules vs. Outbound Rules - Evaluated separately; both required for bidirectional traffic • Default Rules: DenyAllInbound (65500), AllowVNetInbound (65000), AllowAzureLoadBalancerInbound (65001) - cannot delete, can override with higher priority • [Requirement]: Rules are evaluated in priority order; first matching rule applies (stop processing) • Configure Application Security Groups (ASGs): Logical grouping of NICs; simplifies NSG rules (e.g., "Allow WebASG to access DBASG on port 1433") • [Exam Alert]: NSG at subnet AND NIC = cumulative effect (both must allow traffic for it to flow) • Evaluate Effective Security Rules: Azure Portal → NIC → Effective Security Rules (shows combined subnet + NIC rules)
MONITOR (The Verification) ○ Tool/Document: NSG → Monitoring → NSG Flow Logs (requires Storage Account, optionally Log Analytics + Traffic Analytics) ○ Tool/Document: Network Watcher → NSG Diagnostics (troubleshoot why specific traffic is allowed/denied) ○ Metric/Deadline: Review Flow Logs weekly; investigate unexpected Deny actions or unusual traffic patterns
CORE CONCEPT 21: Azure Bastion
PROVISION (The Foundation)
•	Prerequisite: VNet with subnet named "AzureBastionSubnet" (minimum /26, recommend /24 for scalability)
•	Selection: SKU: Basic (no features), Standard (IP-based connection, ShareableLink, sessions monitoring)
•	Execution: Azure Portal → Bastions → Create OR Azure CLI: az network bastion create
CONFIGURE (The Configuration) • Associate Public IP: Azure Bastion requires static Public IP (Standard SKU) • [Critical Distinction]: Azure Bastion vs. Just-in-Time (JIT) VM Access - Bastion is always-on proxy; JIT opens NSG ports temporarily • Configure IP-Based Connection: Standard SKU allows connection to any VM in peered VNets (not just same VNet) • Enable Native Client Support: Allows SSH/RDP from local client via Azure CLI tunnel • [Requirement]: Target VMs do NOT need public IPs or NSG rules allowing internet inbound (Bastion provides secure path) • Scale Out: Standard SKU supports manual scale (2-50 instances) for concurrent sessions
MONITOR (The Verification) ○ Tool/Document: Bastion → Monitoring → Sessions (view active SSH/RDP sessions, connected users) ○ Tool/Document: Bastion → Monitoring → Metrics (Session Count, Data Processed) ○ Metric/Deadline: Monitor Session Count; scale out if consistently reaching instance connection limits
CORE CONCEPT 22: Azure DNS
PROVISION (The Foundation)
•	Prerequisite: Domain name registered with registrar (GoDaddy, Namecheap, etc.) OR Private DNS for VNet resolution
•	Selection: DNS Type: Public DNS Zone (internet-facing domains) vs. Private DNS Zone (VNet name resolution)
•	Execution: Azure Portal → DNS Zones → Create OR Azure CLI: az network dns zone create
CONFIGURE (The Configuration) • Configure Public DNS Zone: Create zone (e.g., contoso.com), update registrar's nameservers to Azure's NS records • Add DNS Records: A (IPv4), AAAA (IPv6), CNAME (alias), MX (mail), TXT (verification), SRV (service discovery) • [Critical Distinction]: Alias Record vs. CNAME - Alias supports apex domain (@), CNAME does not; Alias updates automatically if target IP changes • Configure Private DNS Zone: Create zone (e.g., contoso.internal), link to VNets for automatic VM registration • [Requirement]: Private DNS Zone requires VNet Link with "Auto-registration" enabled for automatic VM DNS entries • Configure Conditional Forwarding: For hybrid scenarios, DNS forwarder (VM with DNS server role) forwards queries to on-premises DNS • [Exam Alert]: Azure-provided DNS (168.63.129.16) resolves Azure-internal names only; custom DNS servers require manual config
MONITOR (The Verification) ○ Tool/Document: DNS Zone → Monitoring → Query Volume (tracks query counts, query types, response codes) ○ Tool/Document: Network Watcher → IP Flow Verify (includes DNS resolution validation) ○ Metric/Deadline: Monitor DNS query failures; investigate NXDOMAIN responses >5% of queries
CORE CONCEPT 23: Azure Load Balancer
PROVISION (The Foundation)
•	Prerequisite: Virtual Network (for internal LB) OR Public IP (for external LB)
•	Selection: SKU: Basic (free, limited features) vs. Standard (SLA, Availability Zones, enhanced diagnostics)
•	Selection: Type: Public (internet-facing, public IP frontend) vs. Internal (private IP frontend)
•	Execution: Azure Portal → Load Balancers → Create OR Azure CLI: az network lb create
CONFIGURE (The Configuration) • Configure Frontend IP: Public IP (Standard SKU for zone redundancy) OR Private IP (specify subnet + static IP) • Create Backend Pool: Add VMs, VMSS, or NICs as load-balanced targets • [Critical Distinction]: Backend Pool Association - VMs (whole VM) vs. IP Configurations (specific NIC + IP) • Create Health Probe: Protocol (TCP, HTTP, HTTPS), Port, Interval (default 5s), Unhealthy Threshold (default 2 failures) • [Requirement]: Health Probe must succeed for backend instance to receive traffic; probe failures remove instance from rotation • Create Load Balancing Rule: Frontend IP + Port → Backend Pool + Port, Protocol, Session Affinity (None, Client IP, Client IP + Protocol) • Configure Inbound NAT Rule: Direct specific port on frontend IP to specific backend instance (e.g., RDP to individual VMs) • [Exam Alert]: Basic Load Balancer does NOT support Availability Zones; Standard LB required for zone-redundant scenarios • Configure Outbound Rules: Standard LB only - control outbound SNAT port allocation, idle timeout
MONITOR (The Verification) ○ Tool/Document: Load Balancer → Monitoring → Metrics (Health Probe Status, Data Path Availability, SNAT Connection Count) ○ Tool/Document: Load Balancer → Backend Health (shows per-instance health probe results) ○ Metric/Deadline: Alert on Health Probe Status <100%; investigate backend instance failures within 15 minutes
CORE CONCEPT 24: User-Defined Routes (UDRs) and Network Troubleshooting
PROVISION (The Foundation)
•	Prerequisite: VNet with subnets requiring custom routing behavior
•	Selection: Next Hop Type: Virtual Appliance, Virtual Network Gateway, VNet, Internet, None (drop traffic)
•	Execution: Azure Portal → Route Tables → Create → Add Routes OR Azure CLI: az network route-table create
CONFIGURE (The Configuration) • Create Route Table: Define custom routes overriding Azure's default system routes • Define Routes: Address Prefix (CIDR), Next Hop Type, Next Hop IP Address (for Virtual Appliance) • [Critical Distinction]: System Routes vs. User-Defined Routes - UDRs override system routes for same prefix; 0.0.0.0/0 UDR forces all internet traffic through appliance • Associate Route Table: Bind to subnet (one route table per subnet, but one route table can serve multiple subnets) • [Requirement]: Network Virtual Appliance (NVA) must have IP Forwarding enabled on its NIC for traffic routing • Configure Border Gateway Protocol (BGP): VPN Gateway can propagate on-premises routes to Azure via BGP
MONITOR (The Verification) ○ Tool/Document: Network Watcher → Next Hop (shows effective next hop for traffic from specific VM to destination IP) ○ Tool/Document: Network Watcher → Connection Troubleshoot (end-to-end diagnostics showing hops, latency, packet drops) ○ Tool/Document: Network Interface → Effective Routes (displays combined system + user-defined routes) ○ Metric/Deadline: Use Connection Troubleshoot immediately when connectivity issues reported; capture results before config changes
═══════════════════════════════════════════════════════════════════════
DOMAIN 5: MONITOR AND MAINTAIN AZURE RESOURCES (10-15%)
CORE CONCEPT 25: Azure Monitor Metrics and Logs
PROVISION (The Foundation)
•	Prerequisite: Resources must exist (metrics collected automatically), Log Analytics Workspace for logs
•	Selection: Log Analytics Workspace: Region (choose near resources), Retention (30-730 days, affects cost)
•	Execution: Azure Portal → Log Analytics Workspaces → Create OR Azure CLI: az monitor log-analytics workspace create
CONFIGURE (The Configuration) • Configure Diagnostic Settings: Resource → Monitoring → Diagnostic Settings → Send to Log Analytics, Storage, Event Hub, or Partner solution • [Critical Distinction]: Metrics vs. Logs - Metrics are numeric time-series (CPU %, memory), lightweight, 93-day retention; Logs are text records, heavier, custom retention • Select Log Categories: AllMetrics, AuditLogs, SecurityLogs, OperationalLogs (varies by resource type) • [Requirement]: Diagnostic Settings must be configured PER RESOURCE (does not inherit from resource groups) • Query Logs: Kusto Query Language (KQL) in Log Analytics Workspace • [Example KQL]: AzureActivity | where TimeGenerated > ago(1h) | where Level == "Error" • Enable VM Insights: Deploys Azure Monitor Agent + Dependency Agent to VMs for performance/dependency mapping • Configure Data Collection Rules: Define which data to collect, transformation rules, destination workspaces
MONITOR (The Verification) ○ Tool/Document: Azure Monitor → Metrics Explorer (multi-resource charts, aggregation, filtering) ○ Tool/Document: Log Analytics Workspace → Logs (KQL query interface for cross-resource log analysis) ○ Metric/Deadline: Run critical queries hourly; save as Functions for reuse across dashboards/alerts
CORE CONCEPT 26: Azure Monitor Alerts and Action Groups
PROVISION (The Foundation)
•	Prerequisite: Metric/Log data source OR Activity Log event to monitor
•	Selection: Alert Type: Metric Alert (numeric threshold), Log Search Alert (KQL query result), Activity Log Alert (subscription/resource events)
•	Execution: Azure Portal → Monitor → Alerts → Create Alert Rule OR Azure CLI: az monitor metrics alert create
CONFIGURE (The Configuration) • Define Alert Condition: Metric (static or dynamic threshold, aggregation period), Log Search (query result count/metric), Activity Log (specific operations) • [Critical Distinction]: Static Threshold vs. Dynamic Threshold - Static uses fixed value (CPU >80%); Dynamic uses ML to adapt baseline • Create Action Group: Recipients (email, SMS, voice, push), Actions (Automation Runbook, Azure Function, Logic App, Webhook) • [Requirement]: Action Groups are reusable across multiple alert rules (best practice: create per-team action groups) • Configure Alert Processing Rules: Suppress alerts during maintenance windows, add action groups globally, route based on resource type/tags • Set Severity: 0 (Critical) to 4 (Verbose) affects prioritization and potential routing logic • [Exam Alert]: Log Search Alerts have delay (up to 10 min) due to log ingestion latency; not suitable for real-time sub-minute alerting
MONITOR (The Verification) ○ Tool/Document: Monitor → Alerts → Alert History (view triggered alerts, state changes, action group executions) ○ Tool/Document: Monitor → Alerts → Alert Rules (enable/disable rules, view last evaluated status) ○ Metric/Deadline: Review alert effectiveness monthly; tune thresholds to reduce false positives <10% of total alerts
CORE CONCEPT 27: Monitoring Specific Resource Types
PROVISION (The Foundation)
•	Prerequisite: Target resource (VM, Storage Account, Virtual Network) must exist
•	Selection: Monitoring Tool: Azure Monitor Insights (VMs, Containers, Networks, Storage), Resource-specific metrics
•	Execution: Enable from resource's Monitoring section OR deploy monitoring agents
CONFIGURE (The Configuration) • VM Monitoring: Enable VM Insights (guest OS performance, processes, dependencies), Boot Diagnostics (serial console, screenshots) • Storage Account Monitoring: Enable Storage Analytics Logs (blob/queue/table/file requests), Metrics (transactions, latency, availability) • [Critical Distinction]: Platform Metrics vs. Guest Metrics - Platform collected by Azure (host level); Guest requires agent (OS level) • Network Monitoring: Enable Network Watcher (packet capture, connection monitor, VPN diagnostics) • Configure Connection Monitor: Continuous testing between source (VM) and destination (endpoint/URL/VM), tracks latency/loss • Enable IP Flow Verify: Test if packet allowed/denied by NSG rules (source/dest IP, port, protocol) • Enable Packet Capture: Capture network packets to storage account for deep analysis (max duration 5 hours) • [Requirement]: Connection Monitor requires Network Watcher extension installed on source VM
MONITOR (The Verification) ○ Tool/Document: VM Insights → Performance (CPU, memory, disk, network charts), Map (application dependencies) ○ Tool/Document: Storage Account → Insights → Overview (capacity, transactions, latency by service type) ○ Tool/Document: Network Watcher → Connection Monitor (test results, path visualization, hop-by-hop metrics) ○ Metric/Deadline: Review Connection Monitor tests daily; investigate failures or latency >100ms increase
CORE CONCEPT 28: Azure Backup
PROVISION (The Foundation)
•	Prerequisite: Recovery Services Vault (for VMs, Files) OR Azure Backup Vault (for Azure Disks, Blobs, Database)
•	Selection: Vault Type: Recovery Services Vault (most common), Backup Vault (newer services)
•	Selection: Geo-Redundancy: LRS (vault replicated locally), GRS (vault replicated to paired region for DR)
•	Execution: Azure Portal → Recovery Services Vaults → Create OR Azure CLI: az backup vault create
CONFIGURE (The Configuration) • Create Backup Policy: Schedule (daily/weekly), Retention (daily, weekly, monthly, yearly retention points), Backup window • [Example Policy]: Daily backup at 2 AM, retain 7 daily, 4 weekly, 12 monthly, 5 yearly backups • Configure VM Backup: Select VMs, assign policy, Azure Backup extension auto-installs on VM • [Critical Distinction]: Full Backup vs. Incremental Backup - First backup is full; subsequent are incremental (only changed blocks) • Enable Azure Files Backup: Share-level backup (no agent required), supports snapshots • Configure Soft Delete: Deleted backups retained 14-90 days (protects against accidental deletion/ransomware) • [Requirement]: Soft Delete enabled by default (can disable, but not recommended) • Set Backup Alerts: Email/Webhook notifications for backup failures, restore completion, policy changes • [Exam Alert]: Azure Backup for VMs requires VMs to be in "Running" or "Stopped (deallocated)" state; "Stopped (allocated)" VMs cannot back up
MONITOR (The Verification) ○ Tool/Document: Recovery Services Vault → Monitoring → Backup Jobs (view job status, duration, data transferred) ○ Tool/Document: Recovery Services Vault → Monitoring → Backup Reports (Power BI integration, trend analysis) ○ Metric/Deadline: Target RPO (Recovery Point Objective) <24 hours for VMs; alert on backup failures within 6 hours
CORE CONCEPT 29: Azure Site Recovery
PROVISION (The Foundation)
•	Prerequisite: Recovery Services Vault in target region, Azure-to-Azure replication OR VMware/Hyper-V to Azure
•	Selection: Replication Scenario: Azure VM to Azure (region-to-region), On-Premises to Azure, Secondary Site to Primary Site
•	Execution: Azure Portal → Recovery Services Vault → Site Recovery → Replicate Application
CONFIGURE (The Configuration) • Enable Replication: Source region → Target region, select VMs, configure target resources (VNet, storage account, availability set/zone) • [Critical Distinction]: Azure Backup vs. Site Recovery - Backup for data protection/restore; Site Recovery for disaster recovery/failover of entire workloads • Configure Replication Policy: Crash-consistent snapshot every 5 min (default), App-consistent snapshot every 1-12 hours • [Requirement]: Mobility Service auto-installs on Azure VMs (for Azure-to-Azure), manual install for on-premises VMs • Create Recovery Plan: Group VMs, define failover order, add manual actions/scripts, integrate with Azure Automation • Perform Test Failover: Creates isolated copy in target region without impacting production (uses test VNet) • [Exam Alert]: Test failover must be cleaned up manually (does not auto-delete test VMs) • Execute Planned Failover: For planned maintenance (syncs data, shuts down source, starts target, minimal data loss) • Execute Unplanned Failover: For disaster (uses latest recovery point, source VMs may not be gracefully shut down)
MONITOR (The Verification) ○ Tool/Document: Recovery Services Vault → Site Recovery → Replicated Items (view replication health, RPO, last recovery point) ○ Tool/Document: Recovery Services Vault → Site Recovery → Recovery Plans (view failover history, test results) ○ Metric/Deadline: Target RPO <15 minutes for critical VMs; alert on Replication Health "Critical" or RPO >1 hour
CORE CONCEPT 30: Backup and Recovery Operations
PROVISION (The Foundation)
•	Prerequisite: Backup Policy configured and initial backup completed for target resource
•	Selection: Recovery Point: Latest, Point-in-Time (specific date/time), Crash-consistent vs. App-consistent
•	Execution: Azure Portal → Recovery Services Vault → Backup Items → Restore
CONFIGURE (The Configuration) • Restore VM: Restore Type - Create new VM, Replace existing VM, Restore disks only • [Critical Distinction]: Create New VM vs. Replace Existing VM - Create New preserves original; Replace overwrites (irreversible) • Configure Restore Location: Same region (default), Alternate region (requires GRS vault, secondary region restore) • Restore Azure Files: File-level restore (mount snapshot and copy files) OR Share-level restore (entire share) • Enable Cross-Region Restore: GRS vaults allow restore to Azure paired region (even during primary region outage) • [Requirement]: Cross-Region Restore must be explicitly enabled in vault properties (not enabled by default on GRS) • Perform Item-Level Recovery: For VMs with file-level restore, mount recovery point as iSCSI disk to source/alternate VM • Configure Instant Restore: Azure Backup stores snapshots for 1-5 days locally (fast recovery <2 hours) before vault transfer
MONITOR (The Verification) ○ Tool/Document: Recovery Services Vault → Monitoring → Restore Jobs (track restore progress, success/failure) ○ Tool/Document: Recovery Services Vault → Monitoring → Backup Alerts (configure critical alerts for backup failures) ○ Metric/Deadline: Target RTO (Recovery Time Objective) <4 hours for critical VMs; test restore quarterly to validate

---

## **4. VISUAL MENTAL ANCHORS**

### **Anchor 1: The Three-Story Security Building (Identity, Access, Resource)**

**Visualization:** Picture a modern three-story office building with a sophisticated security system. The **Ground Floor Lobby** (Microsoft Entra ID - Identity Layer) is where everyone receives their employee badge—this is your identity credential that proves WHO you are (user account, group membership, MFA enrollment). You can't enter the building at all without a valid badge. The **elevator and badge readers on each floor** (RBAC - Authorization Layer) determine WHICH FLOORS and rooms you can access based on your role—an intern's badge might only open the first floor (Reader role), while a senior engineer's badge opens floors 1-2 (Contributor role), and only the CTO's badge opens all three floors plus the executive suite (Owner role). The badge reader checks your role scope: building-wide access (Management Group scope), floor access (Subscription scope), specific wing access (Resource Group scope), or individual room access (Resource scope). Finally, the **security cameras and motion sensors on every floor** (Azure Policy - Governance Layer) enforce the building's rules about WHAT ACTIONS are allowed regardless of who you are—even the CTO can't smoke in the building, can't prop open fire exits, or can't store flammable materials in the office (policies like "All VMs must have encryption," "No public IP addresses on production VMs"). The cameras (compliance scans) check every room every day and flag violations.

**Why It Helps:** Clarifies the fundamental difference between authentication (proving identity), authorization (granting access), and governance (enforcing rules), and prevents the common mistake of thinking "I'm the Owner, so Policy doesn't apply to me." Students wrongly assume that RBAC Owner role means unlimited power, but Azure Policy operates independently—a Contributor can deploy VMs, but if a policy says "Only B-series VMs allowed," even an Owner can't deploy D-series VMs. The three-story building makes it physically obvious that: (1) you must pass through Ground Floor security FIRST before accessing anything (authentication is the prerequisite), (2) your elevator access is hierarchical and inherited downward (Owner at subscription level flows to all resource groups below), and (3) building rules apply to everyone equally (policies evaluate at resource create time regardless of role). This prevents exam errors where students think role assignments can bypass policy restrictions, or where they assign Reader when they meant Contributor, not realizing Reader cannot modify resources even though they can see them.

---

### **Anchor 2: The Storage Account Swiss Army Knife (Four Tools, Four Purposes)**

**Visualization:** Picture a red Swiss Army knife with four distinct tools folded into one handle—the handle represents your Storage Account (the billing/management container), and each tool serves a different purpose but shares the same security/networking configuration. **Tool 1: The Saw Blade** (Blob Storage) is designed for cutting through large volumes of unstructured data—video files, images, backups, data lakes—anything that doesn't fit into rows and columns. The saw has three settings etched into it: "Hot" (sharp teeth, frequent use, more expensive but fast), "Cool" (medium teeth, occasional use, cheaper), and "Archive" (locked in a protective sleeve, rarely used, must wait hours to unlock before use). **Tool 2: The File** (Azure Files) is the traditional SMB file share tool—imagine a metal file with ridges—that Windows servers have used for decades. You can mount it like a Z: drive on any VM, and it supports the same permissions and folders as your on-premises file server. **Tool 3: The Corkscrew** (Queue Storage) is a spiral tool for passing small messages in order—imagine messages as wine corks lined up, each one containing a job instruction. Apps pull one cork at a time, process the instruction, then discard it. **Tool 4: The Tiny Screwdriver** (Table Storage) is for lightweight NoSQL data—think of a screwdriver with replaceable bits representing key-value pairs. Unlike SQL databases, there's no rigid schema; each row (entity) can have different columns (properties).

**Why It Helps:** Prevents the common mistake of choosing the wrong storage type for the use case, which causes significant exam failure. Students wrongly assume "storage is storage" and don't realize that Blob Storage is immutable by default (perfect for backups, terrible for file shares), Azure Files supports SMB protocols that Blobs don't (you can't map Blob storage as a drive letter), Queue Storage is designed for decoupling app components (not for storing large data), and Table Storage lacks complex query capabilities that SQL databases provide. The Swiss Army knife metaphor makes it physically obvious that: (1) all four tools share the same handle (storage account keys, firewall rules, encryption settings apply to all four services), (2) each tool has a specific job—you wouldn't use a corkscrew to file wood—so don't use Table Storage for video files or Blob Storage for VM-mounted drives, and (3) some tools have mode settings (Hot/Cool/Archive access tiers for Blobs, no such tiers for Files). This prevents exam scenarios where students deploy Azure Files for massive data lakes (wrong—Blob wins for big data) or try to mount Blob Storage as a network drive (wrong—Azure Files required).

---

### **Anchor 3: The Load Balancer Traffic Cop (Four Lanes, Health Checkpoint, Rule Book)**

**Visualization:** Picture a busy highway intersection where a **traffic cop** (Azure Load Balancer) stands in the center managing four lanes of incoming traffic. The **four lanes** (Frontend IPs—one public IP, three private IPs) each represent different sources of requests: the public internet lane (internet-facing apps), the internal corporate network lane (intranet apps), the database subnet lane (backend services), and the management tools lane (admin access). Each incoming vehicle (network packet) has a destination written on its roof—"Port 443 HTTPS," "Port 3389 RDP," or "Port 1433 SQL." The traffic cop consults a **giant rule book** (Load Balancing Rules) strapped to their belt: "All vehicles from Public IP Lane heading to Port 443 → distribute across Backend Pool A (three web servers), using round-robin rotation." Before directing traffic, the cop looks down the highway at a **health checkpoint station** (Health Probe) where each backend server must check in every 5 seconds by flashing its lights (responding to probe on port 80)—if a server stops flashing (2 consecutive failures), the cop puts up a "Road Closed" sign for that lane and stops directing traffic there until lights reappear. The cop also manages **special VIP lanes** (Inbound NAT Rules) where certain vehicles get direct escort to a specific server—"Any vehicle from Public IP on Port 50001 goes DIRECTLY to Server1 on Port 3389 for RDP, no load balancing."

**Why It Helps:** Clarifies the relationship between Frontend IPs, Backend Pools, Health Probes, Load Balancing Rules, and Inbound NAT Rules—five distinct components that students constantly confuse. Students wrongly assume that just creating a Load Balancer automatically distributes traffic, not realizing that RULES are what define the mapping. The traffic cop metaphor makes it physically obvious that: (1) multiple frontend IPs allow different entry points for different traffic types (public vs. private), (2) the rule book explicitly maps "Frontend IP + Port" → "Backend Pool + Port" (if no rule exists for Port 22, SSH traffic won't flow even if backend servers support SSH), (3) health probes are REQUIRED for automatic failover—without them, the cop blindly sends traffic to failed servers—and (4) Inbound NAT Rules bypass load balancing for administrative access (like RDP to individual VMs behind a load balancer). This prevents exam failures where students configure a Backend Pool with VMs but forget to create a Load Balancing Rule (traffic never flows), or where they wonder why traffic still goes to a broken server (no health probe configured, so cop doesn't know it's failed), or where they need to RDP to a specific backend VM but can't because they didn't set up an Inbound NAT Rule for unique port mapping.

---

## **5. WORKED EXAMPLE**

### **Student Question:**
"I deployed an Azure VM running a web application in the East US region. I configured an NSG at the subnet level allowing HTTP (port 80) from anywhere (0.0.0.0/0). I also attached a second NSG to the VM's network interface with a rule allowing RDP (port 3389) from my office IP only. When I try to browse the website from my laptop, it times out. When I try to RDP from my office, that also times out. But when I run `ping <VM_Public_IP>` from my laptop, I get replies. What's misconfigured?"

---

### **Chart Navigation:**

**Step 1: Identify the Domain and Core Concept**
→ **DOMAIN 4: Implement and Manage Virtual Networking** (This is clearly a networking/connectivity issue)
→ **CORE CONCEPT 20: Network Security Groups (NSGs)** (Issue involves NSG rules and traffic flow)

**Step 2: Check the Foundation (Provision Phase)**
→ Review: "Association: Subnet-level (applies to all resources in subnet) vs. NIC-level (applies to single VM)"
→ Observation: Student has BOTH subnet-level NSG AND NIC-level NSG (this is valid—dual-layer security)

**Step 3: Check the Configuration Phase**
→ Review Critical Distinction: "Inbound Rules vs. Outbound Rules - Evaluated separately; both required for bidirectional traffic"
→ Review Requirement: "Rules are evaluated in priority order; first matching rule applies (stop processing)"
→ Review Exam Alert: "NSG at subnet AND NIC = cumulative effect (both must allow traffic for it to flow)"

**Step 4: Check the Verification Tools**
→ Tool identified: "NSG → Monitoring → NSG Flow Logs" and "Network Watcher → NSG Diagnostics"
→ Recommended immediate action: "Network Watcher → IP Flow Verify (test if packet allowed/denied to specific IP)"

---

### **The Diagnosis:**

Using the **PROVISION → CONFIGURE → MONITOR** structure reveals the issue:

1. **Foundation Analysis (Provision Phase):** 
   - The VM exists and has a public IP (ping succeeds, confirming network path is functional at IP layer)
   - Two NSGs are correctly associated: one at subnet level, one at NIC level
   - Both NSGs are required to allow traffic for it to reach the VM (cumulative effect)

2. **Configuration Analysis (Configure Phase):**
   - Subnet NSG allows HTTP (port 80) inbound from 0.0.0.0/0 ✓
   - NIC NSG allows RDP (port 3389) inbound from office IP ✓
   - **PROBLEM IDENTIFIED:** The NIC-level NSG has NO rule explicitly allowing HTTP port 80
   - Since NSGs are cumulative, traffic must pass BOTH the subnet NSG AND the NIC NSG
   - HTTP traffic is allowed by subnet NSG but hits NIC NSG's default **DenyAllInbound** rule (priority 65500)
   - RDP traffic has a rule at the NIC level BUT is not allowed by the subnet NSG (subnet only allows port 80)
   - ICMP (ping) succeeds because both NSGs allow it via the **AllowVNetInbound** default rule (priority 65000)

3. **Specific Misconfiguration:**
   - Chart's Critical Distinction explains: "NSG at subnet AND NIC = cumulative effect (both must allow traffic for it to flow)"
   - Chart's Configuration section states: "Default Rules: DenyAllInbound (65500)...cannot delete, can override with higher priority"
   - Translation: Even though subnet NSG allows port 80, the NIC NSG's default DenyAllInbound rule blocks it
•	Even though NIC NSG allows port 3389, the subnet NSG has no rule for port 3389, so subnet's DenyAllInbound blocks it
________________________________________
The Solution:
Immediate Actions (derived from Chart's Configuration section):
1.	Fix HTTP Access: 
o	Add rule to NIC-level NSG: Priority 100, Source: Any (0.0.0.0/0), Destination: Any, Port: 80, Protocol: TCP, Action: Allow
o	This ensures HTTP traffic passes both subnet NSG (already allows) AND NIC NSG (new rule allows)
2.	Fix RDP Access: 
o	Add rule to Subnet-level NSG: Priority 200, Source: [Office IP/32], Destination: Any, Port: 3389, Protocol: TCP, Action: Allow
o	This ensures RDP traffic passes both subnet NSG (new rule allows) AND NIC NSG (already allows)
3.	Verify Using Chart's Monitoring Tools: 
o	Navigate to VM's Network Interface → Effective Security Rules (Chart: "shows combined subnet + NIC rules")
o	Confirm both HTTP (80) and RDP (3389) show "Allow" in the effective rules list
o	Use Network Watcher → IP Flow Verify to test: 
	Test 1: Source=Laptop IP, Destination=VM Public IP, Port=80, Protocol=TCP → Should show "Access Allowed"
	Test 2: Source=Office IP, Destination=VM Public IP, Port=3389, Protocol=TCP → Should show "Access Allowed"
________________________________________
Learning Point:
Why the three-phase PROVISION → CONFIGURE → MONITOR structure solved this problem:
1.	Foundation Phase (Provision) established the topology: The chart immediately identified that the student had a valid but complex dual-NSG configuration (both subnet and NIC level). Without understanding the Foundation section's "Association" guidance, students often don't realize they've created a layered security model.
2.	Configuration Phase exposed the cumulative logic: The chart's "Exam Alert: NSG at subnet AND NIC = cumulative effect" is the critical rule that students miss. Most students think "I allowed port 80 at the subnet, so it should work"—they don't realize that EVERY NSG in the path must have an allow rule. The Configuration section's explicit statement about "both must allow traffic" immediately pinpointed why HTTP was failing (blocked by NIC NSG) and RDP was failing (blocked by subnet NSG).
3.	Verification Phase provided diagnostic tools: Instead of guessing or randomly modifying rules, the Monitor section directed the student to two specific tools: Effective Security Rules (shows the merged result of all NSGs) and IP Flow Verify (tests specific source/destination/port combinations). These tools prove whether the fix worked BEFORE the student wastes time testing from their laptop.
Key Insight: The hierarchical chart structure prevented the "random config changes" troubleshooting anti-pattern. By walking through Provision (understand the setup) → Configure (identify the rule gap) → Monitor (verify the fix), the student solved the problem systematically in under 10 minutes instead of spending hours trial-and-error modifying NSG rules. This is exactly how Azure administrators troubleshoot production incidents: understand the topology, analyze the configuration against requirements, then use monitoring tools to validate before declaring success.
________________________________________
END OF AZ-104 VISUAL MASTER HIERARCHICAL CHART


